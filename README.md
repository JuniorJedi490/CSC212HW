# CSC212HW
Automated Emotion- and Rhythm-Based Robot Choreography with Fall-Checking Algorithm based on the work of Junyun Tay

# Abstract
Robotic choreography and dance has been an important research topic for years. Automated choreography research dates back to at least 2005, when Washington University researchers presented an algorithm to design routines for animated characters (Alankus, Bayazit, & Bayazit, 2005, p. 2). In 2012, Carnegie Mellon University’s Guangyu Xia, Junyun Tay, Roger Dannenberg, and Manuela Veloso came up with a new algorithm that bases routines on not only the tempo of the music, but also on an estimation of the emotional theme. Designed with humanoid robots in mind, the Carnegie Mellon researchers’ algorithm implements a system to account for differences in actual and expected movement times. Since then, at least five more choreography and dance algorithms have been developed for humanoid robots (Augello et. al., 2014; Manfrè et al., 2015; Peng et al., 2016; Peng et al., 2018; Qin et. al., 2018), but no one has attempted to re-create the Carnegie Mellon researchers’ results using a different data set. This experiment combines the CMU algorithm with ProFeaSM, a fall-checking algorithm developed by two of the same researchers, and tests the results using a new set of motion primitives based on the Nao robot’s standard behavior library.

# Progress Report - Week 1 (February 9-15)
- Did research. The results of my research are in the "References" section.
- Wrote abstract.

# Progress Report - Week 2 (February 16-22)
- Created GitHub page for project.
- E-mailed authors for original research, did not get source code.

# Todo list for Week 3
- Make flowcharts for all algorithms.
- Code the main algorithm (but not the ones it calls yet)

# References
Alankus, G., Bayazit, A. A. & Bayazit, O. B. (2005). Automated Motion Synthesis for Virtual Choreography. Computer Animation and Virtual Worlds, 16(3/4), 259–271.
Augello, A., Chella, A., Gaglio, S., Infantino, I., Pilato, G., Rizzo, R., & Vella, F. Towards a Cognitive Human Dancer. http://cogsci.eecs.qmul.ac.uk/humanoids/Augelloetal1_2014.pdf
Manfrè, A., Infantino, I., Vella, F., & Gaglio, S. (2016). An automatic system for humanoid dance creation. Biologically Inspired Cognitive Architectures, 15, 1-9. doi:10.1016/j.bica.2015.09.009
Peng, H., Hu, H., Chao, F., Zhou, C., & Li, J. (2016). Autonomous Robotic Choreography Creation via Semi-interactive Evolutionary Computation. International Journal of Social Robotics, 8(5), 649-661. doi:10.1007/s12369-016-0355-x
Peng, H., Li, J., Hu, H. Zhou, C., & Ding, Y. (2018). Robotic Choreography Inspired by the Method of Human Dance Creation. Information, 9(10), 250. doi:10.3390/info9100250
Qin, R., Zhou, C., Zhu, H., Shi, M., Chao, F., & Li, N. (2018). A Music-Driven Dance System of Humanoid Robots. International Journal of Humanoid Robotics, 15(5). doi:10.1142/S0219843618500238
Tay, J., Chen, I., & Veloso, M. (2016). Fall Prediction for New Sequences of Motions. In M. A. Hsieh, O. Khatib, & V. Kumar (Eds.), Experimental Robotics: The 14th International Symposium on Experimental Robotics. (pp. 849-864). C. Springer. doi:10.1007/978-3-319-23778-7_56
Xia, G., Tay, J., Dannenberg, R., & Veloso, M. (2012). Autonomous Robot Dancing Driven by Beats and Emotions of Music. In Proceedings of the 11th International Conference on Autonomous Agents and Multiagent Systems, AAMAS 2012 (pp. 205-212). International Foundation for Autonomous Agents and Multiagent Systems.
